% \chapter{Notations}
% Sample notations \autoref{ta:notations}

% % table of notation
% \setlength{\tabcolsep}{6pt}
% \begin{table} 
% \begin{center} 
% \caption{Mathematical notations}
% \label{ta:notations}
% {\normalsize
% \begin{tabular}{l c}
% \toprule
% Symbol & Meaning \\
% \midrule
%     $\alpha$ & learning rate\\
%     $\gamma$ & discount factor \\
%     $S, s$ &   state \\
%     $A, a$ &   action \\
%     $R, r$ &   reward \\
%     $\tau$ &    a trajectory / an episode \\
%     $G$ &   return \\
%     $t$ &   a discrete time step \\
%     $G_t$ & return at time step t \\
%     $T$ &   final time step of an episode \\
%     $\pi$     & policy \\
%     $\pi_\theta$ & parametrized policy with parameter \theta \\
%     $\pi(s)$ & the action distribution given state $s$ under policy $\pi$ \\
%     $\pi(a|s)$ & probability of action $a$ given state $s$ under policy $\pi$ \\
%     $\E$ & expectation \\
%     $\E_\pi$ & expectation under policy $\pi$ \\
%     $v(s)$ & state value of state $S$ \\
%     $v_\pi(s)$ & state value of state $S$ under policy $\pi$\\
%     $q(s, a)$ & action value of action $a$ on state $s$ \\
%     $q_pi(s, a)$ & action value of action $a$ on state $s$ under policy $\pi$\\
%     $\sigma$ & activation function \\
% \bottomrule
% \end{tabular}
% } \end{center} \end{table}
% \setlength{\tabcolsep}{6pt}




