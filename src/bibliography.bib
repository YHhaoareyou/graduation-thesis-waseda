@incollection{pytorch,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems 32},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {8024--8035},
    year = {2019},
    publisher = {Curran Associates, Inc.},
}

@misc{pokeenv,
    author       = {Haris Sahovic},
    title        = {Poke-env: pokemon AI in python},
    version      = {0.3.10},
    url          = {https://github.com/hsahovic/poke-env}
}

@article{alphago,
    title   = {Mastering the game of Go with deep neural networks and tree search},
    author  = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
    year    = {2016},
    URL = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
    journal = {Nature},
    pages   = {484--503},
    volume  = {529}
}

@article{owidcoronavirus,
    author = {Hannah Ritchie, Edouard Mathieu, Lucas Rodés-Guirao, Cameron Appel, Charlie Giattino, Esteban Ortiz-Ospina, Joe Hasell, Bobbie Macdonald, Diana Beltekian and Max Roser},
    title = {Coronavirus Pandemic (COVID-19)},
    journal = {Our World in Data},
    year = {2020},
    note = {https://ourworldindata.org/coronavirus}
}

@article{AMANKWAHAMOAH2021602,
    title = {COVID-19 and digitalization: The great acceleration},
    journal = {Journal of Business Research},
    volume = {136},
    pages = {602-611},
    year = {2021},
    issn = {0148-2963},
    doi = {https://doi.org/10.1016/j.jbusres.2021.08.011},
    url = {https://www.sciencedirect.com/science/article/pii/S0148296321005725},
    author = {Joseph Amankwah-Amoah and Zaheer Khan and Geoffrey Wood and Gary Knight},
    keywords = {COVID-19, Work and organization, Digitalization, Business model, Business strategies, Emerging technologies},
    abstract = {Inspired by burgeoning scholarly interest in the role of digitalization in the COVID-19 pandemic, this paper examines how the COVID-19 pandemic is driving or constraining the digitalization of businesses around the globe. We contend that COVID‐19 is “the great accelerator” in fast-tracking the existing global trend towards embracing modern emerging technologies ushering in transformations in lifestyle, work patterns, and business strategies. Thus, COVID-19 has evolved to be a kind of “catalyst” for the adoption and increasing use of digitalization in work organization and the office, alongside presenting foreseen and unforeseen opportunities, challenges, and costs—leading to negative and positive feedback loops. In this article, we develop and advance a conceptual model by linking the different forces for and against digitalization in response to the pandemic. Our analysis indicates that adoption of emerging technologies may be hindered by vested external interests, nostalgia, and employer opportunism, as well as negative effects on employee well-being that undermine productivity, work–life balance, and future of work. Whilst digitalization may bring new opportunities, the process imparts risks that may be hard to mitigate or prepare for. Finally, we draw out the wider theoretical and practical implications of our analysis.}
}


@inproceedings{impala,
    title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
    author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
    booktitle={International Conference on Machine Learning},
    pages={1407--1416},
    year={2018},
    organization={PMLR}
}

@Inbook{tdgammon,
    author="Tesauro, Gerald",
    editor="Murray, Alan F.",
    title="TD-Gammon: A Self-Teaching Backgammon Program",
    bookTitle="Applications of Neural Networks",
    year="1995",
    publisher="Springer US",
    address="Boston, MA",
    pages="267--285",
    abstract="This chapter describes TD-Gammon, a neural network that is able to teach itself to play backgammon solely by playing against itself and learning from the results. TD-Gammon uses a recently proposed reinforcement learning algorithm called TD($\lambda$) (Sutton, 1988), and is apparently the first application of this algorithm to a complex nontrivial task. Despite starting from random initial weights (and hence random initial strategy), TD-Gammon achieves a surprisingly strong level of play. With zero knowledge built in at the start of learning (i.e. given only a ``raw'' description of the board state), the network learns to play the entire game at a strong intermediate level that surpasses not only conventional commercial programs, but also comparable networks trained via supervised learning on a large corpus of human expert games. The hidden units in the network have apparently discovered useful features, a longstanding goal of computer games research.",
    isbn="978-1-4757-2379-3",
    doi="10.1007/978-1-4757-2379-3_11",
    url="https://doi.org/10.1007/978-1-4757-2379-3_11"
}

@book{mentalmodel,
    title={World dynamics},
    author={Forrester, Jay W},
    year={1971},
    publisher={Wright-Allen Press}
}
