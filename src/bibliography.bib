@incollection{pytorch,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems 32},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {8024--8035},
    year = {2019},
    publisher = {Curran Associates, Inc.},
}

@misc{pokeenv,
    author       = {Haris Sahovic},
    title        = {Poke-env: pokemon AI in python},
    version      = {0.3.10},
    url          = {https://github.com/hsahovic/poke-env}
}

@article{alphago,
    title   = {Mastering the game of Go with deep neural networks and tree search},
    author  = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
    year    = {2016},
    URL = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
    journal = {Nature},
    pages   = {484--503},
    volume  = {529}
}


@inproceedings{impala,
    title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
    author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
    booktitle={International Conference on Machine Learning},
    pages={1407--1416},
    year={2018},
    organization={PMLR}
}

@Inbook{tdgammon,
    author="Tesauro, Gerald",
    editor="Murray, Alan F.",
    title="TD-Gammon: A Self-Teaching Backgammon Program",
    bookTitle="Applications of Neural Networks",
    year="1995",
    publisher="Springer US",
    address="Boston, MA",
    pages="267--285",
    abstract="This chapter describes TD-Gammon, a neural network that is able to teach itself to play backgammon solely by playing against itself and learning from the results. TD-Gammon uses a recently proposed reinforcement learning algorithm called TD($\lambda$) (Sutton, 1988), and is apparently the first application of this algorithm to a complex nontrivial task. Despite starting from random initial weights (and hence random initial strategy), TD-Gammon achieves a surprisingly strong level of play. With zero knowledge built in at the start of learning (i.e. given only a ``raw'' description of the board state), the network learns to play the entire game at a strong intermediate level that surpasses not only conventional commercial programs, but also comparable networks trained via supervised learning on a large corpus of human expert games. The hidden units in the network have apparently discovered useful features, a longstanding goal of computer games research.",
    isbn="978-1-4757-2379-3",
    doi="10.1007/978-1-4757-2379-3_11",
    url="https://doi.org/10.1007/978-1-4757-2379-3_11"
}

@book{mentalmodel,
    title={World dynamics},
    author={Forrester, Jay W},
    year={1971},
    publisher={Wright-Allen Press}
}
